{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xz6w---77agq"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob, os\n",
        "import numpy as np\n",
        "import gc\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import random\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "88RMGXCx7uSC",
        "outputId": "875a79f5-0f52-4359-bb06-f36e95182126"
      },
      "outputs": [],
      "source": [
        "x_real = np.load('C:/Users/h4uh4/OneDrive/Desktop/Skripsi_Bimbingan/Fingerprint/DataFinal/SOCOFing/dataset/x_easy.npz')['data']\n",
        "x_easy = np.load('C:/Users/h4uh4/OneDrive/Desktop/Skripsi_Bimbingan/Fingerprint/DataFinal/SOCOFing/dataset/x_easy.npz')['data']\n",
        "x_medium = np.load('C:/Users/h4uh4/OneDrive/Desktop/Skripsi_Bimbingan/Fingerprint/DataFinal/SOCOFing/dataset/x_medium.npz')['data']\n",
        "x_hard = np.load('C:/Users/h4uh4/OneDrive/Desktop/Skripsi_Bimbingan/Fingerprint/DataFinal/SOCOFing/dataset/x_hard.npz')['data']\n",
        "y_real = np.load('C:/Users/h4uh4/OneDrive/Desktop/Skripsi_Bimbingan/Fingerprint/DataFinal/SOCOFing/dataset/y_real.npy')\n",
        "y_easy = np.load('C:/Users/h4uh4/OneDrive/Desktop/Skripsi_Bimbingan/Fingerprint/DataFinal/SOCOFing/dataset/y_easy.npy')\n",
        "y_medium = np.load('C:/Users/h4uh4/OneDrive/Desktop/Skripsi_Bimbingan/Fingerprint/DataFinal/SOCOFing/dataset/y_medium.npy')\n",
        "y_hard = np.load('C:/Users/h4uh4/OneDrive/Desktop/Skripsi_Bimbingan/Fingerprint/DataFinal/SOCOFing/dataset/y_hard.npy')\n",
        "\n",
        "print(x_real.shape, y_real.shape)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.subplot(1, 4, 1)\n",
        "\n",
        "plt.title(y_real[0])\n",
        "plt.imshow(x_real[0].squeeze(), cmap='gray')\n",
        "plt.subplot(1, 4, 2)\n",
        "\n",
        "plt.title(y_easy[0])\n",
        "plt.imshow(x_easy[0].squeeze(), cmap='gray')\n",
        "plt.subplot(1, 4, 3)\n",
        "\n",
        "plt.title(y_medium[0])\n",
        "plt.imshow(x_medium[0].squeeze(), cmap='gray')\n",
        "plt.subplot(1, 4, 4)\n",
        "\n",
        "plt.title(y_hard[0])\n",
        "plt.imshow(x_hard[0].squeeze(), cmap='gray')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "FkUiPy9u7vX-",
        "outputId": "b4641755-f019-48dc-8493-3226697c3f11"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "\n",
        "\n",
        "image = cv2.imread('C:/Users/h4uh4/OneDrive/Desktop/Skripsi_Bimbingan/Fingerprint/DataFinal/SOCOFing/Real/1__M_Left_index_finger.BMP')\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "augment = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Affine(scale=(0.9, 1.1), translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, rotate=(-5, 5), p=0.7),\n",
        "\n",
        "\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "augmented = augment(image=image)\n",
        "augmented_image = augmented['image']\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Augmented Image\")\n",
        "plt.imshow(augmented_image)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CeguspV7w4w",
        "outputId": "a013411e-5774-4e68-8d4a-b5fe52f4021d"
      },
      "outputs": [],
      "source": [
        "\n",
        "x_real = x_real[:len(y_real)]\n",
        "\n",
        "\n",
        "x_data = np.concatenate([x_real, x_easy, x_medium, x_hard], axis=0)\n",
        "y_data = np.concatenate([y_real, y_easy, y_medium, y_hard], axis=0)\n",
        "\n",
        "print(f\"x_data shape: {x_data.shape}\")\n",
        "print(f\"y_data shape: {y_data.shape}\")\n",
        "\n",
        "\n",
        "half_size = len(x_data) // 2\n",
        "\n",
        "x_data_half = x_data[:half_size]\n",
        "y_data_half = y_data[:half_size]\n",
        "\n",
        "print(f\"x_data_half shape: {x_data_half.shape}\")\n",
        "print(f\"y_data_half shape: {y_data_half.shape}\")\n",
        "\n",
        "\n",
        "\n",
        "assert x_data_half.shape[0] == y_data_half.shape[0], \"Jumlah sample x_data dan y_data tidak sama!\"\n",
        "\n",
        "\n",
        "x_temp, x_test, y_temp, y_test = train_test_split(x_data_half, y_data_half, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_temp, y_temp, test_size=0.25, random_state=42)\n",
        "\n",
        "\n",
        "print(f\"Train set size: {x_train.shape[0]} samples\")\n",
        "print(f\"Validation set size: {x_val.shape[0]} samples\")\n",
        "print(f\"Test set size: {x_test.shape[0]} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6vmqfKW8mN2",
        "outputId": "a6d476ec-0cd4-40e9-d4e9-70ae5d71532d"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"Memeriksa dataset raw untuk NaN atau Inf...\")\n",
        "\n",
        "if np.any(np.isnan(x_data_half)) or np.any(np.isinf(x_data_half)):\n",
        "    print(\"NaN atau Inf terdeteksi pada dataset raw!\")\n",
        "else:\n",
        "    print(\"Dataset raw bersih dari NaN atau Inf.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lelsnv7i7y2-"
      },
      "outputs": [],
      "source": [
        "\n",
        "x_train = np.expand_dims(x_train, -1).astype('float32') / 255.\n",
        "x_val = np.expand_dims(x_val, -1).astype('float32') / 255.\n",
        "x_test = np.expand_dims(x_test, -1).astype('float32') / 255.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "Uy4GzaUJ7z6L",
        "outputId": "87fdb983-27b8-4047-f02d-5cf1d05b2848"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import psutil\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def apply_gabor_filter(img):\n",
        "    ksize = 15\n",
        "    sigma = 0.75\n",
        "    theta = np.pi / 4\n",
        "    lambda_ = 5.0\n",
        "    gamma = 0.5\n",
        "    psi = 0\n",
        "\n",
        "\n",
        "    gabor_kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambda_, gamma, psi)\n",
        "\n",
        "\n",
        "    filtered_image = cv2.filter2D(img, cv2.CV_32F, gabor_kernel)\n",
        "\n",
        "\n",
        "    filtered_image = np.clip(filtered_image, 0, 255)\n",
        "    filtered_image = filtered_image / 255.0\n",
        "\n",
        "    return filtered_image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x_train_gabor = np.array([apply_gabor_filter(img.squeeze()) for img in x_train])\n",
        "x_val_gabor = np.array([apply_gabor_filter(img.squeeze()) for img in x_val])\n",
        "x_test_gabor = np.array([apply_gabor_filter(img.squeeze()) for img in x_test])\n",
        "\n",
        "\n",
        "print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(x_train[0], cmap='gray')\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(x_train_gabor[0], cmap='gray')\n",
        "plt.title(\"Gabor Filtered Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "gabor_result = apply_gabor_filter(x_train[0])\n",
        "plt.imshow(gabor_result, cmap='gray')\n",
        "plt.title(\"Gabor Filtered Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYGULx0v8I-v",
        "outputId": "b229cc09-3c56-4158-d08f-d4d754dc4d9e"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZwlVHIA8Le5"
      },
      "outputs": [],
      "source": [
        "\n",
        "x_train_gabor = np.nan_to_num(x_train_gabor)\n",
        "x_val_gabor = np.nan_to_num(x_val_gabor)\n",
        "x_test_gabor = np.nan_to_num(x_test_gabor)\n",
        "\n",
        "\n",
        "x_train_gabor = np.expand_dims(x_train_gabor, -1).astype('float32') / np.max(x_train_gabor)\n",
        "x_val_gabor = np.expand_dims(x_val_gabor, -1).astype('float32') / np.max(x_val_gabor)\n",
        "x_test_gabor = np.expand_dims(x_test_gabor, -1).astype('float32') / np.max(x_test_gabor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVUA2pQu8Tza"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "\n",
        "def ensure_rgb(image):\n",
        "    if image.shape[-1] == 1:\n",
        "        image = np.repeat(image, 3, axis=-1)\n",
        "    return image\n",
        "\n",
        "\n",
        "x_train_gabor_rgb = np.array([ensure_rgb(img) for img in x_train_gabor])\n",
        "\n",
        "\n",
        "class PairGenerator(Sequence):\n",
        "    def __init__(self, x, y, x_real, y_real, batch_size=32, augment_fn=None):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.x_real = x_real\n",
        "        self.y_real = y_real\n",
        "        self.batch_size = batch_size\n",
        "        self.augment_fn = augment_fn\n",
        "\n",
        "\n",
        "        self.label_real_dict = {}\n",
        "        for idx, label in enumerate(self.y_real):\n",
        "            key = ''.join(label.astype(str)).zfill(6)\n",
        "            if key not in self.label_real_dict:\n",
        "                self.label_real_dict[key] = []\n",
        "            self.label_real_dict[key].append(idx)\n",
        "\n",
        "        self.label_keys = list(self.label_real_dict.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        start = index * self.batch_size\n",
        "        end = min((index + 1) * self.batch_size, len(self.x))\n",
        "\n",
        "\n",
        "        x1_batch = np.empty((end - start, 96, 96, 3), dtype=np.float32)\n",
        "        x2_batch = np.empty((end - start, 96, 96, 3), dtype=np.float32)\n",
        "        y_batch = self.y[start:end]\n",
        "        batch_size = len(x1_batch)\n",
        "\n",
        "        labels = np.zeros((batch_size, 1), dtype=np.float32)\n",
        "\n",
        "        for i, label in enumerate(y_batch):\n",
        "            key = ''.join(label.astype(str)).zfill(6)\n",
        "\n",
        "            if random.random() > 0.5 and key in self.label_real_dict:\n",
        "                idx = random.choice(self.label_real_dict[key])\n",
        "                x2 = self.x_real[idx]\n",
        "                labels[i] = 1.\n",
        "            else:\n",
        "                while True:\n",
        "                    unmatch_key = random.choice(self.label_keys)\n",
        "                    if unmatch_key != key:\n",
        "                        idx = random.choice(self.label_real_dict[unmatch_key])\n",
        "                        x2 = self.x_real[idx]\n",
        "                        break\n",
        "                labels[i] = 0.\n",
        "\n",
        "            x2_batch[i] = x2\n",
        "\n",
        "\n",
        "            x1_batch[i] = self.x[start + i]\n",
        "            x2_batch[i] = x2\n",
        "\n",
        "\n",
        "            if self.augment_fn:\n",
        "\n",
        "                if isinstance(x1_batch[i], np.ndarray):\n",
        "                    x1_batch[i] = self.augment_fn(image=x1_batch[i])['image']\n",
        "                elif isinstance(x1_batch[i], tf.Tensor):\n",
        "                    x1_batch[i] = self.augment_fn(image=x1_batch[i].numpy())['image']\n",
        "                \n",
        "                if isinstance(x2_batch[i], np.ndarray):\n",
        "                    x2_batch[i] = self.augment_fn(image=x2_batch[i])['image']\n",
        "                elif isinstance(x2_batch[i], tf.Tensor):\n",
        "                    x2_batch[i] = self.augment_fn(image=x2_batch[i].numpy())['image']\n",
        "\n",
        "        return (x1_batch, x2_batch), labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def ensure_rgb(image):\n",
        "    if image.shape[-1] == 1:\n",
        "        image = np.repeat(image, 3, axis=-1)\n",
        "    return image\n",
        "\n",
        "\n",
        "x_train_gabor_rgb = np.array([ensure_rgb(img) for img in x_train_gabor])\n",
        "\n",
        "\n",
        "print(\"Shape of first image after RGB conversion:\", x_train_gabor_rgb[0].shape)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train_gabor_rgb[0])\n",
        "plt.title('First RGB Image')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Image {i} shape:\", x_train_gabor_rgb[i].shape)\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Image {i} min value:\", np.min(x_train_gabor_rgb[i]))\n",
        "    print(f\"Image {i} max value:\", np.max(x_train_gabor_rgb[i]))\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    if x_train_gabor[i].shape[-1] == 1:\n",
        "        plt.imshow(x_train_gabor[i].squeeze(), cmap='gray')\n",
        "    else:\n",
        "        plt.imshow(x_train_gabor[i])\n",
        "    plt.title(f'Image {i} Before RGB Conversion')\n",
        "\n",
        "\n",
        "    rgb_image = ensure_rgb(x_train_gabor[i])\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(rgb_image)\n",
        "    plt.title(f'Image {i} After RGB Conversion')\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "plt.imshow(x_train_gabor_rgb[0])\n",
        "plt.title('First x1 Image')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "PgGou8BO8ZQc",
        "outputId": "309608e6-cb7a-4e48-a440-1e31041fae6d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "\n",
        "def build_vgg19_model(input_shape=(96, 96, 3)):\n",
        "\n",
        "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    \n",
        "\n",
        "    x = layers.Flatten()(base_model.output)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "    model = models.Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "x1 = layers.Input(shape=(96, 96, 3))\n",
        "x2 = layers.Input(shape=(96, 96, 3))\n",
        "\n",
        "\n",
        "vgg_model = build_vgg19_model()\n",
        "\n",
        "\n",
        "f1 = vgg_model(x1)\n",
        "f2 = vgg_model(x2)\n",
        "\n",
        "\n",
        "diff = layers.Subtract()([f1, f2])\n",
        "\n",
        "\n",
        "x = layers.Dense(128, activation='relu')(diff)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "model = models.Model(inputs=[x1, x2], outputs=output)\n",
        "\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk-rtt6Gr0J2",
        "outputId": "2d64c6fa-db42-4dba-bb80-5b7e2f8933fa"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"Memeriksa dataset setelah filter Laplacian...\")\n",
        "\n",
        "if np.any(np.isnan(x_train_gabor_rgb)) or np.any(np.isinf(x_train_gabor_rgb)):\n",
        "    print(\"NaN atau Inf terdeteksi pada dataset yang sudah difilter!\")\n",
        "else:\n",
        "    print(\"Dataset yang sudah difilter bersih dari NaN atau Inf.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvoia7M78a-D"
      },
      "outputs": [],
      "source": [
        "train_gen = PairGenerator(x_train_gabor_rgb, y_train, x_train_gabor_rgb, y_train, batch_size=32, augment_fn=augment)\n",
        "val_gen = PairGenerator(x_val, y_val, x_val, y_val, batch_size=32, augment_fn=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "humiCJ0v9BB5",
        "outputId": "d401b191-55a9-4ab6-f84e-0cd5f3c5a1e9"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(f\"NaN atau Inf terdeteksi pada x_train_gabor setelah filter Gabor: {np.any(np.isnan(x_train_gabor_rgb)) or np.any(np.isinf(x_train_gabor_rgb))}\")\n",
        "\n",
        "\n",
        "print(f\"NaN atau Inf terdeteksi pada x_val_gabor setelah filter Gabor: {np.any(np.isnan(x_val_gabor)) or np.any(np.isinf(x_val_gabor))}\")\n",
        "print(f\"NaN atau Inf terdeteksi pada x_test_gabor setelah filter Gabor: {np.any(np.isnan(x_test_gabor)) or np.any(np.isinf(x_test_gabor))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZLKDw8b8iI0",
        "outputId": "73dd3044-e096-47b4-d800-d6d904d0055b"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', tf.keras.metrics.AUC()])\n",
        "\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('vgg19_best.h5', save_best_only=True, monitor='val_loss')\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=0.0001)\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=10,\n",
        "    callbacks=[checkpoint, early_stop, lr_scheduler],\n",
        "    verbose=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29h3KXJcE1hz"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.save('C:/Users/h4uh4/OneDrive/Desktop/Skripsi_Bimbingan/Fingerprint/Compare/Diagram/BiarGaBingung/VGG/Model_VGG/gabor_vgg19_final_model.keras')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPWmTaI5FJVV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "test_gen = PairGenerator(x_test_gabor, y_test, x_test_gabor, y_test, batch_size=32, augment_fn=None)\n",
        "\n",
        "\n",
        "test_loss, test_accuracy, test_auc = model.evaluate(test_gen)\n",
        "\n",
        "\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "print(f\"Test AUC: {test_auc}\")\n",
        "\n",
        "\n",
        "results = [test_loss, test_accuracy, test_auc]\n",
        "labels = ['Test Loss', 'Test Accuracy', 'Test AUC']\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(labels, results, color=['red', 'green', 'blue'])\n",
        "\n",
        "\n",
        "plt.xlabel('Metric')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Model Evaluation Results')\n",
        "\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
